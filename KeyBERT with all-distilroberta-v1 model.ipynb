{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import warnings\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import textstat\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy import displacy\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129169b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patient_notes = pd.read_csv(\"patient_notes.csv\")\n",
    "#one case number has many pn_num\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "#one case has many feature_num\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train = train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "train = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cc36a",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"pn_history_lower\"] = train[\"pn_history\"].str.lower()\n",
    "regex = re.compile(r'<[^>]+>')\n",
    "train[\"pn_history_noContractions\"] = train[\"pn_history_lower\"].apply(contractions.fix)\n",
    "\n",
    "def remove_unicode_chars(text):\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    return text\n",
    "train[\"pn_history_noUnicode\"] = train[\"pn_history_noContractions\"].apply(remove_unicode_chars)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), \" \",text)\n",
    "    return text\n",
    "train[\"pn_history_noPuncts\"] = train[\"pn_history_noUnicode\"].apply(remove_punctuations)\n",
    "\n",
    "#def remove_stopwords(text):\n",
    "#    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "#train[\"tweet_noStopwords\"] = train[\"tweet_noPuncts\"].apply(remove_stopwords)\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(' +', ' ', text).strip()\n",
    "    return text\n",
    "train[\"pn_history_noES\"] = train[\"pn_history_noPuncts\"].apply(remove_extra_spaces)\n",
    "def lemmatize_text(text):\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "train[\"pn_history_preprocessed\"] = train[\"pn_history_noES\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates([\"pn_history_preprocessed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da73bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a03db9",
   "metadata": {},
   "source": [
    "## Model 1 : using KeyBERT with all-distilroberta-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyBERT(model=\"all-distilroberta-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae740b9",
   "metadata": {},
   "source": [
    "### Extracting 2 keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8a01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for index, row in tqdm(train.iterrows()):\n",
    "    l.append(model.extract_keywords(\n",
    "                row['pn_history_preprocessed'],\n",
    "                top_n=3, \n",
    "                keyphrase_ngram_range=(1, 2),\n",
    "                use_mmr=True, \n",
    "                diversity=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(pd.DataFrame(l, columns=['first_keyword', 'second_keyword', 'third_keyword']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b31d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the file\n",
    "train.to_csv(\"two_keywords_extraction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aa172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprating keyword along with cosine similarity\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train['first_keyword_score'] = train.first_keyword.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train['first_keyword'] = train.first_keyword.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train['second_keyword_score'] = train.second_keyword.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train['second_keyword'] = train.second_keyword.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train['third_keyword_score'] = train.third_keyword.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train['third_keyword'] = train.third_keyword.apply(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"two_keywords_extraction_with_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f1a6a",
   "metadata": {},
   "source": [
    "### Extracting 3 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = []\n",
    "for index, row in tqdm(train.iterrows()):\n",
    "    l.append(model.extract_keywords(\n",
    "                row['pn_history_preprocessed'],\n",
    "                top_n=3,\n",
    "                keyphrase_ngram_range=(1, 3),\n",
    "                use_mmr=True, \n",
    "                diversity=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31daab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_new = train.join(pd.DataFrame(l, columns=['first_keyword_three', 'second_keyword_three', 'third_keyword_three']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3419538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"three_keywords_extraction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23383a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[1]\n",
    "train_new['first_keyword_score_three'] = train_new.first_keyword_three.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new['first_keyword_three'] = train_new.first_keyword_three.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train_new['second_keyword_score_three'] = train_new.second_keyword_three.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new['second_keyword_three'] = train_new.second_keyword_three.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train_new['third_keyword_score_three'] = train_new.third_keyword_three.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new['third_keyword_three'] = train_new.third_keyword_three.apply(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a245250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.to_csv(\"three_keywords_extraction_with_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87100d1f",
   "metadata": {},
   "source": [
    "### Extracting 4 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = []\n",
    "for index, row in tqdm(train.iterrows()):\n",
    "    l.append(model.extract_keywords(\n",
    "                row['pn_history_preprocessed'],\n",
    "                top_n=3,\n",
    "                keyphrase_ngram_range=(1, 4),\n",
    "                use_mmr=True, \n",
    "                diversity=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new['third_keyword_score_three'] = train_new['third_keyword_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_new = train_new.join(pd.DataFrame(l, columns=['first_keyword_four', 'second_keyword_four', 'third_keyword_four']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_new.to_csv(\"four_keywords_extraction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[1]\n",
    "train_new_new['first_keyword_score_four'] = train_new_new.first_keyword_four.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new_new['first_keyword_four'] = train_new_new.first_keyword_four.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train_new_new['second_keyword_score_four'] = train_new_new.second_keyword_four.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new_new['second_keyword_four'] = train_new_new.second_keyword_four.apply(lambda x: func(x))\n",
    "\n",
    "def func(x):\n",
    "    return x[1]\n",
    "train_new_new['third_keyword_score_four'] = train_new_new.third_keyword_four.apply(lambda x: func(x))\n",
    "def func(x):\n",
    "    return x[0]\n",
    "train_new_new['third_keyword_four'] = train_new_new.third_keyword_four.apply(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_new.to_csv(\"all_keywords_with_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a copy\n",
    "train_with_scores = train_new_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7500f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores = pd.read_csv(\"all_keywords_with_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3051965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores = train_with_scores[['id', 'case_num', 'pn_num', 'feature_num', 'annotation', 'location', 'feature_text', 'pn_history', 'pn_history_lower', 'pn_history_noContractions', 'pn_history_noUnicode', 'pn_history_noPuncts', 'pn_history_noES', 'pn_history_preprocessed', 'first_keyword', 'second_keyword', 'third_keyword', 'first_keyword_score', 'second_keyword_score', 'third_keyword_score', 'first_keyword_three', 'second_keyword_three', 'third_keyword_three', 'first_keyword_score_three', 'second_keyword_score_three', 'third_keyword_score_three', 'first_keyword_four', 'second_keyword_four', 'third_keyword_four', 'first_keyword_score_four', 'second_keyword_score_four', 'third_keyword_score_four']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e08f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf67473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_with_scores = train_with_scores.iloc[:,14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88775a2",
   "metadata": {},
   "source": [
    "### Analysing quantiles to choose a threshold value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ed15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.first_keyword_score.quantile([0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.second_keyword_score.quantile([0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.third_keyword_score.quantile([0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e6220",
   "metadata": {},
   "source": [
    "### selecting those keywords which have a cosine similarity more than 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.first_keyword = np.where(train_with_scores.first_keyword_score > 0.25, train_with_scores.first_keyword, np.nan)\n",
    "train_with_scores.second_keyword = np.where(train_with_scores.second_keyword_score > 0.25, train_with_scores.second_keyword, np.nan)\n",
    "train_with_scores.third_keyword = np.where(train_with_scores.third_keyword_score > 0.25, train_with_scores.third_keyword, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.first_keyword_score.median(), train_with_scores.second_keyword_score.median(), train_with_scores.third_keyword_score.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.first_keyword_three = np.where(train_with_scores.first_keyword_score_three > 0.25, train_with_scores.first_keyword_three, np.nan)\n",
    "train_with_scores.second_keyword_three = np.where(train_with_scores.second_keyword_score_three > 0.25, train_with_scores.second_keyword_three, np.nan)\n",
    "train_with_scores.third_keyword_three = np.where(train_with_scores.third_keyword_score_three > 0.25, train_with_scores.third_keyword_three, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43749837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.first_keyword_four = np.where(train_with_scores.first_keyword_score_four > 0.25, train_with_scores.first_keyword_four, np.nan)\n",
    "train_with_scores.second_keyword_four = np.where(train_with_scores.second_keyword_score_four > 0.25, train_with_scores.second_keyword_four, np.nan)\n",
    "train_with_scores.third_keyword_four = np.where(train_with_scores.third_keyword_score_four > 0.25, train_with_scores.third_keyword_four, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores = train_new_new[['id', 'pn_num', 'pn_history_preprocessed']].join(train_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores[:1].third_keyword.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b7f07",
   "metadata": {},
   "source": [
    "### Predicting Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b25927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    all_annotation = []\n",
    "    for annotation in [x.first_keyword, x.second_keyword, x.third_keyword, \n",
    "                       x.first_keyword_three, x.second_keyword_three, x.third_keyword_three,\n",
    "                       x.first_keyword_four, x.second_keyword_four, x.third_keyword_four]:\n",
    "        \n",
    "        if str(annotation) != 'nan':\n",
    "            all_annotation.append(str(annotation))\n",
    "    return list(set(all_annotation))\n",
    "    \n",
    "train_with_scores['predicted_annotation'] = train_with_scores.apply(lambda x: func(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores[['pn_num', 'predicted_annotation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores.to_csv(\"final_annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880643f",
   "metadata": {},
   "source": [
    "## Evaluation Phase 1 : Using Fuzzy Wuzzy Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_scores = pd.read_csv(\"final_annotations\",index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048141e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_notes_test = pd.read_csv(\"patient_notes.csv\")\n",
    "#one case number has many pn_num\n",
    "features_test = pd.read_csv(\"features.csv\")\n",
    "#one case has many feature_num\n",
    "test = pd.read_csv(\"train.csv\")\n",
    "test = test.merge(features_test, on=['feature_num', 'case_num'], how='left')\n",
    "test = test.merge(patient_notes_test, on=['pn_num', 'case_num'], how='left')\n",
    "test = test.merge(train_with_scores[['pn_num', 'pn_history_preprocessed']], on=['pn_num'], how='left')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21481d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(train_with_scores[['pn_num', 'predicted_annotation']], how='left', on='pn_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ce40b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation = test[['pn_num', 'annotation', 'predicted_annotation', 'pn_history', 'pn_history_preprocessed']]\n",
    "evaluation = evaluation[evaluation.annotation != '[]']\n",
    "evaluation['annotation'] = evaluation['annotation'].astype(str)\n",
    "evaluation['ground_truth_annotation'] = evaluation.annotation.apply(lambda x: eval(x))\n",
    "evaluation = evaluation.explode('ground_truth_annotation')\n",
    "evaluation['ground_truth_annotation_junk'] = evaluation.ground_truth_annotation.apply(lambda x: len(str(x)) < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26927087",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluation.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb37b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.ground_truth_annotation_junk.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_pp = evaluation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.explode('predicted_annotation').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation['predicted_annotation'] = evaluation['predicted_annotation'].astype(str)\n",
    "evaluation = evaluation[evaluation.predicted_annotation != '[]']\n",
    "evaluation['prediction'] = evaluation.predicted_annotation.apply(lambda x: eval(x))\n",
    "evaluation = evaluation.explode('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af826724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the columns of interest\n",
    "cols = ['pn_num', \n",
    "       'pn_history_preprocessed', \n",
    "       'ground_truth_annotation',\n",
    "       'prediction']\n",
    "evaluation = evaluation[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the fuzzy wuzzy score\n",
    "def get_fuzzy_wuzzy_score(x):\n",
    "    prediction = x['prediction']\n",
    "    label = x['ground_truth_annotation']\n",
    "    return fuzz.partial_ratio(prediction, label)\n",
    "\n",
    "evaluation['score'] = evaluation.apply(lambda x: get_fuzzy_wuzzy_score(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(evaluation.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140d5ef",
   "metadata": {},
   "source": [
    "### Evaluation Phase 2: Using Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c131f3",
   "metadata": {},
   "source": [
    "#### PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab7171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relevance(x, threshold):\n",
    "    all_predictions = x.groupby(['prediction']).agg({'score': 'max'}).reset_index()\n",
    "    found_predictions = len(all_predictions[all_predictions['score'] >= threshold])\n",
    "    return found_predictions, len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765023e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold_values = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "all_relevant_predictions = pd.DataFrame()\n",
    "\n",
    "for threshold_val in threshold_values:\n",
    "    relevant_predictions = evaluation.groupby(['pn_num']).apply(lambda x: relevance(x, threshold=threshold_val))\n",
    "    relevant_predictions = relevant_predictions.reset_index()\n",
    "    relevant_predictions = pd.DataFrame(relevant_predictions[0].tolist(), index=relevant_predictions.pn_num)\\\n",
    "                            .rename(columns={0:f'found_labels', 1:f'total_predictions'})\\\n",
    "                            .reset_index()\n",
    "    relevant_predictions[f'precision'] = relevant_predictions[f'found_labels'] / relevant_predictions[f'total_predictions']\n",
    "    relevant_predictions['threshold'] = threshold_val\n",
    "    all_relevant_predictions = pd.concat([all_relevant_predictions, relevant_predictions], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad7072",
   "metadata": {},
   "source": [
    "#### RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97897ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(x, threshold):\n",
    "    all_labels = x.groupby(['ground_truth_annotation']).agg({'score': 'max'}).reset_index()\n",
    "    found_labels = len(all_labels[all_labels['score'] >= threshold])\n",
    "    total_predictions = x['prediction'].nunique()\n",
    "    \n",
    "    return found_labels, len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "all_retrieved_predictions = pd.DataFrame()\n",
    "\n",
    "for threshold_val in threshold_values:\n",
    "    retrieved_labels = evaluation.groupby(['pn_num']).apply(lambda x: retrieval(x, threshold=threshold_val))\n",
    "    retrieved_labels = retrieved_labels.reset_index()\n",
    "    retrieved_labels = pd.DataFrame(retrieved_labels[0].tolist(), index=retrieved_labels.pn_num)\\\n",
    "                        .rename(columns={0:f'found_predictions', 1:f'total_labels'})\\\n",
    "                        .reset_index()\n",
    "    retrieved_labels['recall'] = retrieved_labels[f'found_predictions'] / retrieved_labels[f'total_labels']\n",
    "    retrieved_labels['threshold'] = threshold_val\n",
    "    all_retrieved_predictions = pd.concat([all_retrieved_predictions, retrieved_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = all_retrieved_predictions.merge(all_relevant_predictions, how='left', on=['pn_num', 'threshold'])\n",
    "evaluation_df = evaluation_df[['pn_num', 'threshold', 'total_labels', 'total_predictions', 'found_labels', 'found_predictions', 'recall', 'precision']]\n",
    "\n",
    "evaluation_df['f1_score'] = 2 * (evaluation_df['recall'] * evaluation_df['precision']) / (evaluation_df['recall'] + evaluation_df['precision'])\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a897c05",
   "metadata": {},
   "source": [
    "### The below cell can be uncommented and run to check predictions of a particular patient number. This also has a filter for a ground truth annotation / label already present in the dataset and the predictions against it can be checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9302e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run this to check some particular evaluation or annotation\n",
    "#evaluation[(evaluation.pn_num == 82843) & (evaluation.ground_truth_annotation==\"increased appetite\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f80fe",
   "metadata": {},
   "source": [
    "#### Saving Precision, Recall and F1 scores to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f32d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining it with the clinical text\n",
    "all_distill_roberta_evaluation = evaluation_df.merge(test,on=\"pn_num\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distill_roberta_evaluation.to_csv(\"all_distill_roberta_evaluation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df.to_csv(\"all_distill_roberta_evaluation_scores.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
